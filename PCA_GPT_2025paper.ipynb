{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CASE 1. Fully connected Neural Network (in this case a 3 layer version)\n",
        "For 840 paramter version replace model class with\n",
        "\n",
        "class CompactNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(84, 10)\n",
        "        #self.fc2 = nn.Linear(10, 15)\n",
        "        #self.fc3 = nn.Linear(15, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = F.tanh(self.fc1(x))\n",
        "        #x = F.tanh(self.fc2(x))\n",
        "        return (self.fc1(x))\n",
        "\n",
        "model = CompactNN()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from sklearn.decomposition import PCA\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import networkx as nx\n",
        "from scipy.interpolate import interp1d\n",
        "from scipy.signal import savgol_filter\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "from torch.utils.data import Subset, DataLoader, TensorDataset\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "# Steg 1: Load MNIST data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "traindata=10000\n",
        "train_subset = Subset(train_set, range(traindata))\n",
        "test_subset = Subset(test_set, range(1000))\n",
        "\n",
        "train_loader100 = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
        "test_loader100 = DataLoader(test_subset, batch_size=32, shuffle=False)\n",
        "\n",
        "def cartesian_to_polar(img):\n",
        "    center = (img.shape[1] // 2, img.shape[0] // 2)\n",
        "    maxRadius = min(center[0], center[1])\n",
        "    polar_img = cartesian_to_polar_manual(img)\n",
        "    return polar_img\n",
        "\n",
        "def polar_to_cartesian(polar_img):\n",
        "    center = (polar_img.shape[1] // 2, polar_img.shape[0] // 2)\n",
        "    maxRadius = min(center[0], center[1])\n",
        "    cartesian_img = polar_to_cartesian_manual(polar_img)\n",
        "    return cartesian_img\n",
        "\n",
        "def cartesian_to_polar_manual(cartesian_img, output_shape=(28, 28), center=None, max_radius=None):\n",
        "    H, W = output_shape\n",
        "    if center is None:\n",
        "        center = (cartesian_img.shape[1] // 2, cartesian_img.shape[0] // 2)\n",
        "    if max_radius is None:\n",
        "        max_radius = min(center[0], center[1])\n",
        "\n",
        "    polar_img = np.zeros((H, W), dtype=np.float32)\n",
        "    theta_vals = np.linspace(-np.pi, np.pi, H)\n",
        "    radius_vals = np.linspace(0, max_radius, W)\n",
        "\n",
        "    for i, theta in enumerate(theta_vals):\n",
        "        for j, r in enumerate(radius_vals):\n",
        "            x = center[0] + r * np.cos(theta)\n",
        "            y = center[1] + r * np.sin(theta)\n",
        "            x0 = int(np.floor(x))\n",
        "            x1 = min(x0 + 1, cartesian_img.shape[1] - 1)\n",
        "            y0 = int(np.floor(y))\n",
        "            y1 = min(y0 + 1, cartesian_img.shape[0] - 1)\n",
        "            dx = x - x0\n",
        "            dy = y - y0\n",
        "            if 0 <= x0 < cartesian_img.shape[1] and 0 <= y0 < cartesian_img.shape[0]:\n",
        "                top = (1 - dx) * cartesian_img[y0, x0] + dx * cartesian_img[y0, x1]\n",
        "                bottom = (1 - dx) * cartesian_img[y1, x0] + dx * cartesian_img[y1, x1]\n",
        "                polar_img[i, j] = (1 - dy) * top + dy * bottom\n",
        "    polar_img = np.flipud(polar_img)\n",
        "    return np.flipud(polar_img)\n",
        "\n",
        "def polar_to_cartesian_manual(polar_img, output_size=28, center=None, max_radius=None):\n",
        "    H, W = polar_img.shape\n",
        "    if center is None:\n",
        "        center = (output_size // 2, output_size // 2)\n",
        "    if max_radius is None:\n",
        "        max_radius = output_size // 2\n",
        "\n",
        "    cartesian = np.zeros((output_size, output_size), dtype=np.float32)\n",
        "    y_indices, x_indices = np.indices((output_size, output_size))\n",
        "    dx = x_indices - center[0]\n",
        "    dy = y_indices - center[1]\n",
        "    r = np.sqrt(dx**2 + dy**2)\n",
        "    theta = np.arctan2(dy, dx)\n",
        "    r_norm = r / max_radius\n",
        "    theta_norm = (theta + np.pi) / (2 * np.pi)\n",
        "    r_idx = r_norm * (W - 1)\n",
        "    theta_idx = theta_norm * (H - 1)\n",
        "    r0 = np.clip(np.floor(r_idx).astype(int), 0, W - 2)\n",
        "    r1 = r0 + 1\n",
        "    t0 = np.clip(np.floor(theta_idx).astype(int), 0, H - 2)\n",
        "    t1 = t0 + 1\n",
        "    wr = r_idx - r0\n",
        "    wt = theta_idx - t0\n",
        "    val = (\n",
        "        (1 - wr) * (1 - wt) * polar_img[t0, r0] +\n",
        "        wr * (1 - wt) * polar_img[t0, r1] +\n",
        "        (1 - wr) * wt * polar_img[t1, r0] +\n",
        "        wr * wt * polar_img[t1, r1]\n",
        "    )\n",
        "    cartesian[r <= max_radius] = val[r <= max_radius]\n",
        "    return cartesian\n",
        "\n",
        "class CompactNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(84, 12)\n",
        "        self.fc2 = nn.Linear(12, 11)\n",
        "        self.fc3 = nn.Linear(11, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.tanh(self.fc1(x))\n",
        "        x = F.tanh(self.fc2(x))\n",
        "        return (self.fc3(x))\n",
        "\n",
        "model = CompactNN()\n",
        "\n",
        "# ------------------------\n",
        "# Skapa 100 polära bilder från train_subset\n",
        "# ------------------------\n",
        "polar_images = []\n",
        "class_polar_reference = {}\n",
        "seen_classes = set()\n",
        "\n",
        "for img, label in train_subset:\n",
        "    img_np = img.squeeze().numpy()\n",
        "    polar_img = cartesian_to_polar(img_np)\n",
        "    polar_images.append(polar_img)\n",
        "    class_label = label.item() if hasattr(label, 'item') else int(label)\n",
        "    if class_label not in seen_classes:\n",
        "        class_polar_reference[class_label] = polar_img\n",
        "        seen_classes.add(class_label)\n",
        "    if len(seen_classes) == 10:\n",
        "        break\n",
        "\n",
        "# ------------------------\n",
        "# Skapa PCA-bas per klass från referensbilder\n",
        "# ------------------------\n",
        "reference_pca_per_class = {}\n",
        "for cls, polar_img in class_polar_reference.items():\n",
        "    pca_list = []\n",
        "    for i in range(polar_img.shape[1]):  # per vinkelsegment (kolumn)\n",
        "        col = polar_img[:, i].reshape(-1, 1)\n",
        "        if np.any(col):\n",
        "            pca = PCA(n_components=min(3, col.shape[0], col.shape[1]))\n",
        "            try:\n",
        "                pca.fit(col)\n",
        "                pca_list.append(pca)\n",
        "            except Exception:\n",
        "                pca_list.append(None)\n",
        "        else:\n",
        "            pca_list.append(None)\n",
        "    reference_pca_per_class[cls] = pca_list\n",
        "\n",
        "\n",
        "# ------------------------\n",
        "# Extrahera PCA-komponenter för ny bild med klassens referens-PCA\n",
        "# ------------------------\n",
        "# ------------------------\n",
        "def extract_pca_components(image_tensor, label, reference_pca, n_components=3):\n",
        "    img_np = image_tensor.squeeze().numpy()\n",
        "    polar_img = cartesian_to_polar(img_np)\n",
        "    components = []\n",
        "    pca_list = reference_pca[label.item()]\n",
        "    for i in range(polar_img.shape[1]):  # per vinkelsegment (kolumn)\n",
        "        if i >= len(pca_list):\n",
        "            break\n",
        "        pca = pca_list[i]\n",
        "        col = polar_img[:, i].reshape(-1, 1)\n",
        "        if pca is not None:\n",
        "            try:\n",
        "                c = pca.transform(col).flatten()[:n_components]\n",
        "            except Exception:\n",
        "                c = [0.0] * n_components\n",
        "        else:\n",
        "            c = [0.0] * n_components\n",
        "        components.extend(c)\n",
        "    return np.array(components[:84])\n",
        "\n",
        "polar_data = []\n",
        "polar_labels = []\n",
        "\n",
        "for images, labels in train_loader100:\n",
        "    for img, label in zip(images, labels):\n",
        "        pca_vector = extract_pca_components(img, label, reference_pca_per_class)\n",
        "        polar_data.append(pca_vector)\n",
        "        polar_labels.append(label.item())\n",
        "\n",
        "polar_data = torch.tensor(polar_data, dtype=torch.float32)\n",
        "polar_labels = torch.tensor(polar_labels, dtype=torch.long)\n",
        "\n",
        "polar_dataset = TensorDataset(polar_data, polar_labels)\n",
        "\n",
        "polarloader = DataLoader(polar_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "polar_data_test = []\n",
        "polar_labels_test = []\n",
        "\n",
        "for images, labels in test_loader100:\n",
        "    for img, label in zip(images, labels):\n",
        "        pca_vector = extract_pca_components(img, label, reference_pca_per_class)\n",
        "        polar_data_test.append(pca_vector)\n",
        "        polar_labels_test.append(label.item())\n",
        "\n",
        "polar_data_test = torch.tensor(polar_data_test, dtype=torch.float32)\n",
        "polar_labels_test = torch.tensor(polar_labels_test, dtype=torch.long)\n",
        "\n",
        "polar_dataset = TensorDataset(polar_data_test, polar_labels_test)\n",
        "\n",
        "polarloader_test = DataLoader(polar_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "\n",
        "def train_model_new(model, polarloader, optimizer, criterion):\n",
        "    model.train()\n",
        "    for pca_inputs, labels in polarloader:\n",
        "        pca_inputs = torch.from_numpy(np.array(pca_inputs)).float()\n",
        "        outputs = model(pca_inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "def evaluate_model_new(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(20):\n",
        "    train_model_new(model, polarloader, optimizer, criterion)\n",
        "    acc = evaluate_model_new(model, polarloader_test)\n",
        "    print(f\"Epoch {epoch+1}: Accuracy = {acc:.2f}%\")\n",
        "\n",
        "cpu_time = time.time() - start_time\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Trainable parameters: {count_parameters(model):,}, {traindata:,} training data: {cpu_time:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CASE 2: PCA-Constrained Transformer for Text Classification\n",
        "This notebook demonstrates the complete training pipeline for a compact transformer classifier trained on PCA-compressed MiniLM embeddings from the 20 Newsgroups dataset.\n",
        "\n",
        "The process begins by segmenting each document into 100-token blocks, embedding each segment using a pretrained MiniLM model, and then applying PCA independently at each token position. The resulting $100 \\times 70$ compressed representation is used as input to a lightweight 2-layer transformer encoder with approximately 81,000 parameters.\n",
        "\n",
        "Although the model is structurally minimal, it achieves competitive accuracy while using only a fraction of the parameters of standard BERT-based architectures. The notebook serves both as a proof-of-concept for sequence-wise PCA and as a reproducible baseline for further experiments on input compression, model miniaturization, and resource-efficient NLP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Load dataset\n",
        "newsgroups = fetch_20newsgroups(subset='all')\n",
        "texts = newsgroups.data[:8000]\n",
        "labels = newsgroups.target[:8000]\n",
        "\n",
        "# Encode labels\n",
        "y = LabelEncoder().fit_transform(labels)\n",
        "\n",
        "# SentenceTransformer model\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Segment text into 100 tokens per segment\n",
        "def segment_text(text, segment_len=100):\n",
        "    words = text.split()\n",
        "    segments = [\" \".join(words[i:i+segment_len]) for i in range(0, len(words), segment_len)]\n",
        "    return segments[:100] + [\"\"] * max(0, 100 - len(segments))\n",
        "\n",
        "# Embed and PCA\n",
        "embedded_segments = []\n",
        "for text in texts:\n",
        "    segments = segment_text(text)\n",
        "    embeddings = embedder.encode(segments, show_progress_bar=False)\n",
        "    embedded_segments.append(embeddings)\n",
        "\n",
        "X_segmented = np.array(embedded_segments)\n",
        "\n",
        "# Train PCA per segment\n",
        "segment_pcas = []\n",
        "for i in range(100):\n",
        "    segment_i = np.array([doc[i] for doc in X_segmented])\n",
        "    pca = PCA(n_components=70)\n",
        "    pca.fit(segment_i)\n",
        "    segment_pcas.append(pca)\n",
        "\n",
        "# Transform data\n",
        "X_pca = []\n",
        "for doc in X_segmented:\n",
        "    transformed_doc = [segment_pcas[i].transform(doc[i].reshape(1, -1))[0] for i in range(100)]\n",
        "    X_pca.append(np.stack(transformed_doc))\n",
        "\n",
        "X_pca = np.array(X_pca)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to PyTorch\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "train_data = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "test_data = torch.utils.data.TensorDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64)\n",
        "\n",
        "# Positional encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=100):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "# Transformer model that scales with PCA dimension\n",
        "class SmallTransformerClassifier(nn.Module):\n",
        "    def __init__(self, input_dim=70, seq_len=100, n_classes=20):\n",
        "        super().__init__()\n",
        "        d_model = input_dim\n",
        "        dim_feedforward = max(2 * d_model, 4)\n",
        "        n_heads = 2 if d_model >= 4 else 1\n",
        "\n",
        "        self.embedding = nn.Identity()  # no need to project\n",
        "        self.pos_encoder = PositionalEncoding(d_model=d_model, max_len=seq_len)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=n_heads,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
        "        self.classifier = nn.Linear(d_model, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)         # (batch, 100, input_dim)\n",
        "        x = self.pos_encoder(x)\n",
        "        x = self.transformer(x)\n",
        "        x = x.mean(dim=1)             # global average pooling\n",
        "        return self.classifier(x)\n",
        "\n",
        "# Train and evaluate\n",
        "model = SmallTransformerClassifier(input_dim=X_train.shape[-1]).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "device = next(model.parameters()).device\n",
        "\n",
        "# Print total number of model parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total model parameters: {total_params:,}\")\n",
        "\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(xb)\n",
        "        loss = criterion(out, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {total_loss:.2f}\")\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        preds = model(xb).argmax(dim=1)\n",
        "        correct += (preds == yb).sum().item()\n",
        "\n",
        "accuracy = correct / len(y_test) * 100\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CASE 3: Minimal GPT Decoder (Conceptual Prototype)\n",
        "This notebook provides a minimal, conceptual setup for training a GPT-style decoder on PCA-compressed token embeddings. While it is not intended as a fully functional generative model, it demonstrates that the decoder architecture in a transformer can be trained in the same manner as with original, high-dimensional input. The focus is on illustrating the structural compatibility of PCA-reduced inputs with autoregressive training objectives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# ----- Parameters  -----\n",
        "NUM_PCA_COMPONENTS = 70  # up to 100\n",
        "BLOCK_SIZE = 100\n",
        "\n",
        "# ----- Data and tokenizer -----\n",
        "newsgroups = fetch_20newsgroups(subset='train')\n",
        "raw_texts = newsgroups.data[:100]\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# ----- Segmentation function -----\n",
        "def split_into_blocks(text, block_size=BLOCK_SIZE):\n",
        "    encoding = tokenizer(text, truncation=True, max_length=1024, return_tensors='pt')\n",
        "    tokens = tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])\n",
        "    return [tokens[i:i+block_size] for i in range(0, len(tokens)-block_size+1, block_size)]\n",
        "\n",
        "# ----- Find PCA basis from the first 100-token block -----\n",
        "pca_base_block = None\n",
        "for doc in raw_texts:\n",
        "    blocks = split_into_blocks(doc)\n",
        "    for token_block in blocks:\n",
        "        if len(token_block) == BLOCK_SIZE:\n",
        "            pca_base_block = token_block\n",
        "            break\n",
        "    if pca_base_block is not None:\n",
        "        break\n",
        "\n",
        "if pca_base_block is None:\n",
        "    raise ValueError(\"No text with exact 100 tokens was found\")\n",
        "# Convert GPT2 tokens into individual strings\n",
        "base_token_texts = [tokenizer.convert_tokens_to_string([t]) for t in pca_base_block]\n",
        "\n",
        "# MiniLM-embedding\n",
        "base_embeddings = embedder.encode(base_token_texts, convert_to_numpy=True)\n",
        "base_mean = np.mean(base_embeddings, axis=0)\n",
        "base_centered = base_embeddings - base_mean\n",
        "base_gpu = cp.asarray(base_centered)\n",
        "U, S, Vt = cp.linalg.svd(base_gpu, full_matrices=False)\n",
        "\n",
        "# ----- Collect training blocks -----\n",
        "input_tensors = []\n",
        "target_tensors = []\n",
        "\n",
        "for doc in raw_texts:\n",
        "    blocks = split_into_blocks(doc)\n",
        "    for token_block in blocks:\n",
        "        if len(token_block) < BLOCK_SIZE:\n",
        "            continue\n",
        "        token_strs = [tokenizer.convert_tokens_to_string([t]) for t in token_block]\n",
        "        emb = embedder.encode(token_strs, convert_to_numpy=True)\n",
        "        emb_centered = emb - base_mean\n",
        "        emb_gpu = cp.asarray(emb_centered)\n",
        "        proj = emb_gpu @ Vt.T[:, :NUM_PCA_COMPONENTS]\n",
        "        compressed = cp.asnumpy(proj)\n",
        "        ids = tokenizer.convert_tokens_to_ids(token_block)\n",
        "        input_tensors.append(torch.tensor(compressed, dtype=torch.float32))\n",
        "        target_tensors.append(torch.tensor(ids[:BLOCK_SIZE], dtype=torch.long))\n",
        "\n",
        "if len(input_tensors) == 0:\n",
        "    raise RuntimeError(\"No training blocks generated\")\n",
        "\n",
        "input_tensor = torch.stack(input_tensors)\n",
        "target_tensor = torch.stack(target_tensors)\n",
        "\n",
        "# ----- Tiny Transformer Decoder -----\n",
        "class TinyGPTDecoder(nn.Module):\n",
        "    def __init__(self, input_dim=70, seq_len=100, vocab_size=50257):\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "        d_model = input_dim\n",
        "        self.pos_encoder = nn.Parameter(self._positional_encoding(seq_len, d_model), requires_grad=False)\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=2, dim_feedforward=256, batch_first=True)\n",
        "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=2)\n",
        "        self.output_head = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def _positional_encoding(self, seq_len, d_model):\n",
        "        pe = torch.zeros(seq_len, d_model)\n",
        "        position = torch.arange(0, seq_len, dtype=torch.float32).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        return pe.unsqueeze(0)\n",
        "\n",
        "    def forward(self, memory):\n",
        "        tgt = memory + self.pos_encoder[:, :memory.size(1), :]\n",
        "        tgt_mask = torch.triu(torch.ones(self.seq_len, self.seq_len) * float('-inf'), diagonal=1).to(memory.device)\n",
        "        out = self.decoder(tgt, memory, tgt_mask=tgt_mask)\n",
        "        return self.output_head(out)\n",
        "\n",
        "# ----- Training-----\n",
        "model = TinyGPTDecoder(input_dim=NUM_PCA_COMPONENTS).train()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss_history = []\n",
        "\n",
        "for epoch in range(30):\n",
        "    epoch_loss = 0\n",
        "    for x, y in zip(input_tensor, target_tensor):\n",
        "        x = x.unsqueeze(0)\n",
        "        y = y.unsqueeze(0)\n",
        "        output = model(x)\n",
        "        loss = criterion(output.view(-1, output.size(-1)), y.view(-1))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    avg_loss = epoch_loss / len(input_tensor)\n",
        "    loss_history.append(avg_loss)\n",
        "    print(f\"Epoch {epoch+1}: Loss = {avg_loss:.4f}\")\n",
        "\n",
        "# ----- Loss plot -----\n",
        "plt.plot(loss_history, marker='o')\n",
        "plt.title(\"Training loss each epoch\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ----- Inference -----\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model(input_tensor[-1].unsqueeze(0))\n",
        "    top_tokens = torch.argmax(output, dim=-1).squeeze().tolist()\n",
        "    text = tokenizer.decode(top_tokens[:1024], skip_special_tokens=True)\n",
        "\n",
        "print(\"\\nGenerated text from TinyGPTDecoder:\")\n",
        "print(text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CPU vs GPU ------------ PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Causal mask for decoder\n",
        "def generate_causal_mask(seq_len):\n",
        "    mask = torch.triu(torch.ones(seq_len, seq_len) * float('-inf'), diagonal=1)\n",
        "    return mask\n",
        "\n",
        "# PCA-GPT-like minimal decoder\n",
        "class PcaGPTDecoder(nn.Module):\n",
        "    def __init__(self, input_dim=30, seq_len=100, vocab_size=10000):\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "        d_model = input_dim\n",
        "        n_heads = 2 if d_model >= 4 else 1\n",
        "        dim_feedforward = max(4 * d_model, 16)\n",
        "\n",
        "        self.pos_encoder = PositionalEncoding(d_model=d_model, max_len=seq_len)\n",
        "        decoder_layer = nn.TransformerDecoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=n_heads,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=2)\n",
        "        self.output_head = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x_memory, tgt_input):\n",
        "        causal_mask = generate_causal_mask(self.seq_len).to(tgt_input.device)\n",
        "        x = self.pos_encoder(tgt_input)\n",
        "        out = self.decoder(x, x_memory, tgt_mask=causal_mask)\n",
        "        return self.output_head(out)\n",
        "\n",
        "# Sinusoidal positional encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=100):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "# PCA Tankeexperiment\n",
        "if __name__ == \"__main__\":\n",
        "    model_name = 'all-MiniLM-L6-v2'\n",
        "    embedder = SentenceTransformer(model_name)\n",
        "    base_sentence = (\n",
        "        \"In the realm of ideas everything depends on enthusiasm... in the real world all rests on perseverance. \"\n",
        "        \"This quote repeats itself again and again until we reach precisely one hundred words to test how much can be reconstructed \"\n",
        "        \"through PCA analysis when fed into a transformer embedding model like MiniLM. Let's see how well it holds up. \"\n",
        "        * 2\n",
        "    )\n",
        "    original_sentence = (\n",
        "    \"Artificial intelligence is transforming the world across industries. From autonomous vehicles to personalized medicine, \"\n",
        "    \"AI systems are learning to interpret complex patterns and make decisions with minimal human input. By training models on massive datasets, \"\n",
        "    \"researchers have unlocked capabilities once thought to be science fiction. Still, challenges remain, including explainability, bias, and energy usage. \"\n",
        "    \"Continued innovation in efficient architectures, such as transformer models and knowledge distillation, will be key. \"\n",
        "    * 2\n",
        ")\n",
        "\n",
        "    base_tokens = base_sentence.strip().split()\n",
        "    tokens = original_sentence.strip().split()\n",
        "    base_segments = base_tokens[:100]\n",
        "    segments = tokens[:100]\n",
        "    embeddings = embedder.encode(segments)\n",
        "    base_embeddings = embedder.encode(base_segments)\n",
        "\n",
        "    print(\"Original sentence:\")\n",
        "    print(f\"Original tensor shape: {embeddings.shape} (tokens × dimensions)\")\n",
        "    print(\" \".join(segments))\n",
        "    start_cpu = time.time()\n",
        "    match_scores = []\n",
        "    n_components_list = [10,20,30,40,50,60,70]\n",
        "\n",
        "    for n_components in n_components_list:\n",
        "        pca = PCA(n_components=n_components)\n",
        "        Z_base = pca.fit_transform(base_embeddings)\n",
        "        Z = pca.transform(embeddings)\n",
        "        X_reconstructed = pca.inverse_transform(Z)\n",
        "\n",
        "        # Cosine similarity per token\n",
        "        similarities_cpu = cosine_similarity(embeddings, X_reconstructed)\n",
        "        diagonal_sim = np.mean(np.diag(similarities_cpu))\n",
        "\n",
        "        # Rekonstruera token-ord genom närmsta grann\n",
        "        reconstructed_tokens = []\n",
        "        for i in range(len(segments)):\n",
        "            sims = cosine_similarity([X_reconstructed[i]], embeddings)[0]\n",
        "            best_match_idx = np.argmax(sims)\n",
        "            reconstructed_tokens.append(segments[best_match_idx])\n",
        "\n",
        "        print(\"\\nReconstructed:\")\n",
        "        print(\" \".join(reconstructed_tokens))\n",
        "        print(\"Original:\")\n",
        "        print(\" \".join(segments))\n",
        "\n",
        "        match_count = sum([segments[i] == reconstructed_tokens[i] for i in range(len(segments))])\n",
        "        match_percentage = 100 * match_count / len(segments)\n",
        "        match_scores.append(match_percentage)\n",
        "\n",
        "        print(f\"Match rate: {match_percentage:.2f}%\")\n",
        "\n",
        "    # Plotta träffprocent\n",
        "\n",
        "    plt.plot(n_components_list, match_scores, marker='o', color='black')\n",
        "    plt.xlabel('Number of PCA Components', color='black')\n",
        "    plt.ylabel('Token Match Rate (%)', color='black')\n",
        "    plt.title('Token Reconstruction Accuracy vs PCA Dimension', color='black')\n",
        "    plt.xticks(color='black')\n",
        "    plt.yticks(color='black')\n",
        "    plt.grid(True, color='gray', linestyle='--', linewidth=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "cpu_time = time.time() - start_cpu\n",
        "# PCA-bas från base_embeddings\n",
        "base_mean = np.mean(base_embeddings, axis=0)\n",
        "base_centered = base_embeddings - base_mean\n",
        "base_gpu = cp.asarray(base_centered)\n",
        "mean_gpu = cp.asarray(base_mean)\n",
        "\n",
        "start_gpu = time.time()\n",
        "U, S, Vt = cp.linalg.svd(base_gpu, full_matrices=False)\n",
        "\n",
        "# Nu: projicera nya embeddings mot referensbas\n",
        "emb_centered = embeddings - base_mean\n",
        "emb_gpu = cp.asarray(emb_centered)\n",
        "Z_gpu = emb_gpu @ Vt.T[:, :40]\n",
        "X_reconstructed_gpu = Z_gpu @ Vt[:40, :] + mean_gpu\n",
        "cp.cuda.Device().synchronize()\n",
        "gpu_time = time.time() - start_gpu\n",
        "print(f\"CPU PCA time: {cpu_time:.6f} seconds\")\n",
        "print(f\"GPU PCA time: {gpu_time:.6f} seconds\")\n",
        "\n",
        "\n",
        "# Cosine likhet CPU\n",
        "similarities_cpu = cosine_similarity(embeddings, X_reconstructed)\n",
        "score_cpu = np.mean(np.diag(similarities_cpu))\n",
        "\n",
        "# Cosine likhet GPU\n",
        "similarities_gpu = cosine_similarity(embeddings, cp.asnumpy(X_reconstructed_gpu))\n",
        "\n",
        "score_gpu = np.mean(np.diag(similarities_gpu))\n",
        "\n",
        "print(f\"Mean cosine similarity (CPU reconstruction): {score_cpu:.4f}\")\n",
        "print(f\"Mean cosine similarity (GPU reconstruction): {score_gpu:.4f}\")\n",
        "\n",
        "\n",
        "# ----- Tokenrekonstruktion från GPU -----\n",
        "X_rec_np = cp.asnumpy(X_reconstructed_gpu)\n",
        "reconstructed_tokens_gpu = []\n",
        "for i in range(len(X_rec_np)):\n",
        "    sims = cosine_similarity([X_rec_np[i]], embeddings)[0]\n",
        "    best_match_idx = np.argmax(sims)\n",
        "    reconstructed_tokens_gpu.append(tokens[best_match_idx])\n",
        "\n",
        "print(\"\\nReconstructed text from GPU:\")\n",
        "print(\" \".join(reconstructed_tokens_gpu))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}